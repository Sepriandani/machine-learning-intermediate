# -*- coding: utf-8 -*-
"""boot-sandal-shoe-clasification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TqOsavcB4Rm6-YizVp4yym4NTv2066i0
"""

!pip install split_folders

!pip install kaggle

import tensorflow as tf
import zipfile
import os
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
from keras.preprocessing.image import ImageDataGenerator
from google.colab import files
import splitfolders
from tensorflow.keras.preprocessing import image

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images

# ekstrak file zip
local_zip = '/content/shoe-vs-sandal-vs-boot-dataset-15k-images.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

# Buat directori baru untuk menyimpan data train dan val
train = r'/content/data/train'
val = r'/content/data/val'
if not os.path.exists(train):
    os.makedirs(train)
if not os.path.exists(val):
    os.makedirs(val)

# copy file ke folder train dan val dengan rasio 6:4 atau 60% dan 40%
splitfolders.ratio("/content/Shoe vs Sandal vs Boot Dataset", output="/content/data",seed=1337, ratio=(.8, .2), group_prefix=None)

# Buat path yang mengarah ke directori train dan val
base_dir = '/content/data'
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')

# menampilkan isi directori train
os.listdir(train_dir)

# menampilkan isi directori val
os.listdir(val_dir)

train_datagen = ImageDataGenerator(
                rescale=1./255,
                rotation_range=20,
                horizontal_flip=True,
                shear_range = 0.2,
                fill_mode = 'nearest')
validation_datagen = ImageDataGenerator(rescale = 1.0/255)

train_generator = train_datagen.flow_from_directory(
        train_dir,  
        target_size=(150,150),
        batch_size=32,
        class_mode='categorical')
 
validation_generator = validation_datagen.flow_from_directory(
        val_dir, 
        target_size=(150,150), 
        batch_size=32,
        class_mode='categorical')

train_generator.class_indices

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model.add(tf.keras.layers.MaxPooling2D(2, 2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(2, 2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(2, 2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(3, activation='softmax'))

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.95):
      print("\nAkurasi model telah mencapai 92%")
      self.model.stop_training = True
callbacks = myCallback()

# compile
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(
      train_generator,
      validation_data=validation_generator,
      epochs= 20,
      batch_size=128,
      verbose=2,
      callbacks=[callbacks]
)

# evaluasi performa model yang telah dibuat
def eval_plot(history):

  plt.figure(figsize=(14, 5))

  # Accuracy plot
  plt.subplot(1, 2, 1)
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  epochs = range(len(acc))
  acc_plot, = plt.plot(epochs, acc, 'r')
  val_acc_plot, = plt.plot(epochs, val_acc, 'b')
  plt.title('Training and Validation Accuracy')
  plt.legend([acc_plot, val_acc_plot], ['Training Accuracy', 'Validation Accuracy'])

  # Loss plot
  plt.subplot(1, 2, 2)
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  epochs = range(len(loss))
  loss_plot, = plt.plot(epochs, loss, 'r')
  val_loss_plot, = plt.plot(epochs, val_loss, 'b')
  plt.title('Training and Validation Loss')
  plt.legend([loss_plot, val_loss_plot], ['Training Loss', 'Validation Loss'])

eval_plot(history)

# fungsi untuk prediksi gambar
def predict_image(image_upload, model = model):
  im = image_upload
  im_array = np.asarray(im)
  im_array = im_array*(1/225)
  im_input = tf.reshape(im_array, shape = [1, 150, 150, 3])

  probabilitas = sorted(model.predict(im_input)[0])[2]
  classes = np.argmax(model.predict(im_input))

  if classes == 0:
      label = 'Boot'
  elif classes == 1:
      label = 'Sandal'
  elif classes == 2:
      label = 'Shoe'
  else:
      label = 'Unknown'

  print('\n')
  plt.show()
  print("\nHasil Klasifikasi Gambar: ", label)
  print("Probability: ", round(probabilitas*100,2), "%")
  print('\n')

uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  img = np.vstack([x])

predict_image(img)

# Convert model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save model
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)